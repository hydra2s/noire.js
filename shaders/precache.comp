#version 460 core
#extension GL_GOOGLE_include_directive : enable
#extension GL_ARB_separate_shader_objects : enable
#extension GL_EXT_ray_query : enable
#extension GL_EXT_ray_tracing : enable
#extension GL_EXT_shader_explicit_arithmetic_types_int64 : enable
#extension GL_EXT_shader_explicit_arithmetic_types_int32 : enable
#extension GL_EXT_shader_explicit_arithmetic_types_int16 : enable
#extension GL_EXT_shader_explicit_arithmetic_types_float16 : enable
#extension GL_EXT_nonuniform_qualifier : enable
#extension GL_EXT_scalar_block_layout : enable
#extension GL_EXT_buffer_reference : enable
#extension GL_EXT_buffer_reference2 : enable
#extension GL_EXT_samplerless_texture_functions : enable
#extension GL_EXT_shared_memory_block : enable
#extension GL_EXT_shader_atomic_float : enable

//
#include "include/hlsl_map.glsl"
#include "include/math.glsl"
#include "include/noire.glsl"

//
layout (local_size_x = 32, local_size_y = 6, local_size_z = 1) in;

//
void main() {
    const uvec2 coord = gl_GlobalInvocationID.xy;
    const vec3 bary = texelFetch(FBOF[framebuffers[_BARY]], ivec3(coord, 0), 0).xyz;
    const uvec4 sys = texelFetch(FBOU[framebuffers[_INDICES]], ivec3(coord, 0), 0);

    //
    f16vec4 normal = f16vec4(0.f, 0.f, 0.5f, 0.f);
    vec3 NOR = normalize((modelView[0] * vec4(0.f, 0.f, 0.5f, 0.f)).xyz);
    float hitT = 0.f;

    //
    vec4 _camera = divW(vec4((vec2(coord)/vec2(width, height)*2.f-1.f)*(1.f, 1.f), 1.f, 1.f) * inverse(perspective));
    vec4 _origin = (_camera * modelViewInverse[0]);
    vec3 dir = normalize((modelView[0] * vec4(normalize(_camera.xyz), 0.f)).xyz);
    vec3 origin = _origin.xyz;

    //
    if (any(greaterThan(bary, 0.0001f.xxx))) {
        nrNode nodeData = nrNode(nodeBuffer) + sys.x;
        nrMesh meshData = nrMesh(nodeData.meshBuffer);
        nrGeometry geometryData = nrGeometry(meshData.address) + sys.y;
        uvec3 indices = readIndexData3(geometryData.indice, sys.z);
        vec4 texcoord = readFloatData3(geometryData.texcoord, indices) * bary;

        //
        nrMaterial materialData = nrMaterial(geometryData.materialAddress);

        //
        vec4 pos = divW(texelFetch(FBOF[framebuffers[_POSITION]], ivec3(coord, 0), 0));
        _camera = divW(pos * inverse(perspective));
        _origin = divW(_camera * modelViewInverse[0]);
        dir = normalize((modelView[0] * vec4(normalize(_camera.xyz), 0.f)).xyz);
        origin = _origin.xyz;

        //
        uint64_t materialAddress = geometryData.materialAddress;

        // Hosico
        NOR = normalize((readFloatData3(geometryData.normal, indices) * bary).xyz);
        NOR = normalize((nodeData.transformInverse * vec4(NOR, 0.0f)).xyz);
        NOR = faceforward(NOR, dir, NOR);

        // TOO PISSFUL for FPS
        vec4 TAN = readFloatData3(geometryData.tangent, indices) * bary;
        TAN.xyz = normalize((nodeData.transformInverse * vec4(normalize(TAN.xyz), 0.f)).xyz) * TAN.w;
        TAN.xyz = normalize(TAN.xyz - dot(TAN.xyz, NOR) * NOR);
        // tangent.xyz = faceforward(tangent.xyz, dir, tangent.xyz);

        //
        vec3 BIN = normalize(cross(TAN.xyz, NOR));

        //
        f16vec4 emissive = f16vec4(readTexData(materialData.emissive, texcoord.xy));
        f16vec4 diffuse = f16vec4(readTexData(materialData.diffuse, texcoord.xy));
        f16vec4 normal = f16vec4(readTexData(materialData.normal, texcoord.xy));
        f16vec4 PBR = f16vec4(readTexData(materialData.PBR, texcoord.xy));
        diffuse.xyz = pow(diffuse.xyz, 2.2hf.xxx);

        //
        vec3 viewNormal = (modelViewInverse[0] * vec4(NOR.xyz, 0.0)).xyz;
        vec3 texNormal = mat3(TAN.xyz, BIN.xyz, NOR.xyz) * (normal.xyz * 2.0 - 1.0);

        //
        imageSetStoreF(_DIFFUSE, ivec2(coord), diffuse, 0);
        imageSetStoreF(_TBNDATA, ivec2(coord), f16vec4(texNormal.xyz, 0.0), 0);
        imageSetStoreF(_TBNDATA, ivec2(coord), f16vec4(TAN.xyz, 0.0), 1);
        imageSetStoreF(_TBNDATA, ivec2(coord), f16vec4(BIN.xyz, 0.0), 2);
        imageSetStoreF(_TBNDATA, ivec2(coord), f16vec4(NOR.xyz, 0.0), 3);

        //
        const vec4 currentMeta = imageSetLoadF(_METAPBR, ivec2(gl_GlobalInvocationID.xy), 0);
        imageSetStoreF(_METAPBR, ivec2(gl_GlobalInvocationID.xy), vec4(currentMeta.r, PBR.gb, currentMeta.w), 0);
    } else {
        //
        vec4 _camera = divW(vec4((vec2(gl_GlobalInvocationID.x, gl_GlobalInvocationID.y)/vec2(width, height)*2.f-1.f)*vec2(1.f, -1.f), 1.f, 1.f) * inverse(perspective));
        vec4 _origin = (_camera * modelViewInverse[0]);
        dir = normalize((modelView[0] * vec4(normalize(_camera.xyz), 0.f)).xyz);
        dir.y *= -1.f;
        origin = _origin.xyz;

        //
        const vec4 env = texture(nonuniformEXT(sampler2D(textures[nonuniformEXT(backgroundImageView)], samplers[nonuniformEXT(linearSampler)])), lcts(dir));
        imageSetStoreF(_DIFFUSE, ivec2(coord), vec4(env), 0);
        imageSetStoreF(_TBNDATA, ivec2(coord), vec4(NOR.xyz, 0.0), 0);
        imageSetStoreF(_TBNDATA, ivec2(coord), vec4(0.0.xxx, 0.0), 1);
        imageSetStoreF(_TBNDATA, ivec2(coord), vec4(0.0.xxx, 0.0), 2);
        imageSetStoreF(_TBNDATA, ivec2(coord), vec4(NOR.xyz, 0.0), 3);
        imageSetStoreF(_METAPBR, ivec2(gl_GlobalInvocationID.xy), vec4(0.f.xxx, 0.f), 0);
    }
}
